blocking-io-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 16
  }
  throughput = 1
}

postgres {
  host = "localhost"
  host = ${?POSTGRES_HOST}
  port = "5432"
  port = ${?POSTGRES_PORT}
  database = "postgres"
  database = ${?POSTGRES_DB}
  user = "postgres"
  user = ${?POSTGRES_USER}
  password = "password"
  password = ${?POSTGRES_PASSWORD}
}

s3 {
  internal-bucket = "test-internal-bucket"
  internal-bucket = ${?S3_INTERNAL_BUCKET}
  asset-bucket = "test-asset-bucket"
  asset-bucket = ${?S3_ASSET_BUCKET}
  asset-key-prefix = "dataset-assets"
  asset-key-prefix = ${?S3_ASSET_KEY_PREFIX}
  region = "us-east-1"
  region = ${?S3_REGION}
  copy-chunk-size = 4294967296  # 4Gib (max that will fit into an Int)
  copy-chunk-size = ${?S3_COPY_CHUNK_SIZE}
  copy-chunk-parallelism = 8
  copy-file-parallelism = 4
}

alpakka.s3 {
  aws {
    region {
      provider = default
      default-region = "us-east-1"
      default-region = ${?S3_REGION}
    }
  }
}


akka.http {
  host-connection-pool {
    # Bump timeout to avoid "Substream Source cannot be materialized more than
    # once" error when copying huge files. This is safe since the publish job
    # will eventually consume the response entities, or fail entirely.
    response-entity-subscription-timeout = 60.seconds

    # Increase connection limit per-host since all requests will go to S3.  This
    # should be approximately copy-file-parallelism * copy-chunk-parallelism.
    max-connections = 32

    # Cap number of *buffered* requests waiting for a connection, per-pool. See
    # [1] for a good description of the behavior or `max-open-requests` and
    # `max-connections`. Also [2] for implementation. The docs are not clear on
    # this but `max-open-requests` needs to be larger than `max-connections` to
    # actually buffer requests
    #
    # [1] https://www.gregbeech.com/2018/04/08/akka-http-client-pooling-and-parallelism/
    # [2] https://github.com/akka/akka-http/blob/997f01ad72b5560df3b1a3d5a305eba333987d30/akka-http-core/src/main/scala/akka/http/impl/engine/client/PoolInterface.scala#L71-L75
    max-open-requests = 256

   # Some additional links for context on entity subscription and pool problems:
   #
   # https://github.com/akka/akka-http/issues/2120
   # https://github.com/akka/alpakka/issues/2296
   # https://github.com/akka/akka-http/issues/3134
  }
  client {
    # changed from default to reduce the chances of getting akka.stream.SubscriptionWithCancelException$NoMoreElementsNeeded$
    # errors during multipart copy of large files during publish.
    #
    # Suggested here: https://discuss.lightbend.com/t/about-nomoreelementsneeded-exception/8599
    stream-cancellation-delay = 1 second
  }
}
